{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re \n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "\tblob = TextBlob(text)\n",
    "\treturn blob.sentiment.polarity\n",
    "\n",
    "\n",
    "def analyze_subjectivity(text):\n",
    "\tblob = TextBlob(text)\n",
    "\treturn blob.sentiment.subjectivity\n",
    "\n",
    "\n",
    "def read_text_file(filename):\n",
    "\treturn clear_text(open(filename).read())\n",
    "\t\n",
    "\n",
    "def clear_text(text):\n",
    "\treturn re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\tprint (analyze_sentiment(augur))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from numpy import mean\n",
    "from xmljson import badgerfish as bf\n",
    "from xml.etree.ElementTree import fromstring\n",
    "\n",
    "\n",
    "COINGECKO_MAIN = 'https://www.coingecko.com/en'\n",
    "\n",
    "AUGUR_SUBREDDIT = 'https://www.reddit.com/r/Augur/'\n",
    "\n",
    "\n",
    "NEXT_PAGE_PATTERN = '\\?count=\\d+&amp;after=[^\"]+'\n",
    "SECOND_NEXT_PAGE_PATTERN = '\\?amp=&amp;count=\\d+&amp;after=[^\"]+'\n",
    "\n",
    "\n",
    "def scrap_text(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Chrome/75.0.3770.90 '}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    return res.text\n",
    "\n",
    "\n",
    "def get_coin_fundementals():\n",
    "    raw_text = scrap_text(COINGECKO_MAIN).replace(\"\\n\", \"\")\n",
    "    rows = re.findall(\"<tr>.+?</tr>\", raw_text)\n",
    "    for row in rows:\n",
    "        # if \"monero\" in row:\n",
    "        try:\n",
    "            name = re.findall(r\"crypto-symbol text-muted'>(.+?)</span>\", row)[0]\n",
    "            hash_algo = re.findall(r\"<small>(.+?)</small>\", row)[0]\n",
    "            print( \"NAME:\", name)\n",
    "            print (\"HASH ALGO:\", hash_algo)\n",
    "            print\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "def parse_xml(raw):\n",
    "    return bf.data(fromstring(raw))\n",
    "\n",
    "\n",
    "def get_titles(subreddit_url):\n",
    "    raw_text = scrap_text(subreddit_url)\n",
    "    titles = re.findall('<a class=\"title.+?>(.+?)<', raw_text)\n",
    "    next_url_suffix = re.findall(NEXT_PAGE_PATTERN, raw_text)\n",
    "    next_url_suffix2 = re.findall(SECOND_NEXT_PAGE_PATTERN, raw_text)\n",
    "    if next_url_suffix or next_url_suffix2:\n",
    "        next_url_suffix = next_url_suffix if next_url_suffix else  next_url_suffix2\n",
    "        number = int(re.findall(\"count=(\\d+)\", next_url_suffix[0])[0])\n",
    "        if number > 100:\n",
    "            return titles\n",
    "        next_url = subreddit_url.split(\"?\")[0] + next_url_suffix[0]\n",
    "        return titles + get_titles(next_url)\n",
    "\n",
    "    return titles\n",
    "\n",
    "\n",
    "def average_sentiment(text, ignore_zeros=True, negative_only=False):\n",
    "    if negative_only:\n",
    "        return mean([x for x in [analyze_sentiment(line) for line in text] if x < 0])\n",
    "    if ignore_zeros:\n",
    "        return mean([x for x in [analyze_sentiment(line) for line in text] if x != 0])\n",
    "    return mean([analyze_sentiment(line) for line in text])\n",
    "\n",
    "\n",
    "def average_subjectivity(text, ignore_zeros=True, negative_only=False):\n",
    "    if negative_only:\n",
    "        return mean([x for x in [analyze_subjectivity(line) for line in text] if x < 0])\n",
    "    if ignore_zeros:\n",
    "        return mean([x for x in [analyze_subjectivity(line) for line in text] if x != 0])\n",
    "    return mean([analyze_subjectivity(line) for line in text])\n",
    "\n",
    "\n",
    "def full_analysis(currency_name, subreddit_url):\n",
    "    titles = get_titles(subreddit_url)\n",
    "    sentiment = average_sentiment(titles)\n",
    "    subjectivity = average_subjectivity(titles)\n",
    "\n",
    "    print (currency_name + \":\")\n",
    "    print (\"Sentiment:\", sentiment)\n",
    "    print (\"Subjectivity:\", subjectivity)\n",
    "    print\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_coin_fundementals()\n",
    "    quit()\n",
    "    full_analysis(\"Augur\", AUGUR_SUBREDDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
